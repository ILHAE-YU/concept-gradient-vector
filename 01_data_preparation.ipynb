{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import ants\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we expect the data structure to be like this:\n",
    "# data_path/                            # data root\n",
    "# ├── 3000/                             # subject number\n",
    "# │   └── Reconstructed_DaTSCAN/        # imaging type\n",
    "# │       └── 2011-01-20_16_28_47.0/    # examination date\n",
    "# │           └── I323662/              # imaging ID\n",
    "# │               └── ...dicom          # dicom files\n",
    "# ├── 3001/\n",
    "# ...  \n",
    "data_path = \"./data/DaT_raw\"\n",
    "\n",
    "# we expect the data table at least contains the following columns:\n",
    "# Image Data ID : [Ixxxxxxx, Dxxxxxxx], Image identifiers\n",
    "# Subject       : xxxxxx, Subject ID\n",
    "# Group         : [PD, Control, SWEDD], Diagnostic group\n",
    "# Sex           : [F, M], Sex\n",
    "# Age           : xx, Age\n",
    "# Visit         : [SC, V02, V04, V06, V08, V10, ...], Visit timepoint\n",
    "# Acq Date      : DD/MM/YYYY, Acqusition Date\n",
    "table_path = \"./data/DaT_raw.csv\"\n",
    "\n",
    "# we expect the Striatal Binding Ratio analysis table at least contains the following columns:\n",
    "# PATNO                 : xxxxxx, Subject ID\n",
    "# EVENT_ID              : [SC, V02, V04, V06, V08, V10, ...], Screening timepoint\n",
    "# DATSCAN_CAUDATE_R     : xxx, SBR value\n",
    "# DATSCAN_CAUDATE_L     : xxx, SBR value\n",
    "# DATSCAN_PUTAMEN_R     : xxx, SBR value\n",
    "# DATSCAN_PUTAMEN_L     : xxx, SBR value\n",
    "# DATSCAN_PUTAMEN_R_ANT : xxx, SBR value\n",
    "# DATSCAN_PUTAMEN_L_ANT : xxx, SBR value\n",
    "sbr_table_path = \"./data/DaT_SBR_Analysis.csv\"\n",
    "\n",
    "# All of the above data is accessible in the same format on the PPMI.\n",
    "# https://www.ppmi-info.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abcb306",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./data/DaT_nii\"\n",
    "\n",
    "####################\n",
    "\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "failure_list = []\n",
    "\n",
    "def convert_dicom_to_nifti(dicom_directory, output_directory):\n",
    "    global success_count\n",
    "    global failure_count\n",
    "    global failure_list\n",
    "    try:\n",
    "        subprocess.run(['dcm2niix', '-o', output_directory, dicom_directory], check=True)\n",
    "        success_count += 1\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        failure_list.append(dicom_directory)\n",
    "        failure_count += 1\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "subs = os.listdir(data_path)\n",
    "for sub in tqdm(subs, desc=\"Convert\"):\n",
    "    files = os.listdir(os.path.join(data_path, sub))\n",
    "    os.makedirs(os.path.join(save_path, sub), exist_ok=True)\n",
    "    for file in files:\n",
    "        dates = os.listdir(os.path.join(data_path, sub, file))\n",
    "        os.makedirs(os.path.join(save_path, sub, file), exist_ok=True)\n",
    "        for date in dates:\n",
    "            os.makedirs(os.path.join(save_path, sub, file, date), exist_ok=True)\n",
    "            iids = os.listdir(os.path.join(data_path, sub, file, date))\n",
    "            for iid in iids:\n",
    "                os.makedirs(os.path.join(save_path, sub, file, date, iid), exist_ok=True)\n",
    "                dcm_path = os.path.join(data_path, sub, file, date, iid)\n",
    "                nii_path = os.path.join(save_path, sub, file, date, iid)\n",
    "                os.makedirs(nii_path, exist_ok=True)\n",
    "                convert_dicom_to_nifti(dcm_path, nii_path)\n",
    "\n",
    "\n",
    "print(\"converting done.\")\n",
    "print(f\"success: {success_count}, failure: {failure_count}\")\n",
    "if failure_count > 0:\n",
    "    print(f\"failure list: {failure_list}\")\n",
    "print(f\"result files are saved in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple inspection filtering\n",
    "\n",
    "data_path       = \"./data/DaT_nii\"\n",
    "table_path      = \"./data/DaT_raw.csv\"\n",
    "\n",
    "save_path       = \"./data/DaT_nii_multi_inspection_filtering\"\n",
    "table_save_path = \"./data/DaT_nii_multi_inspection_filtering.csv\"\n",
    "extension = '.nii'\n",
    "\n",
    "############################################\n",
    "\n",
    "def find_substring_in_list(s, lst):\n",
    "    for i, element in enumerate(lst):\n",
    "        if s in element:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def find_files_with_extension(path, extension):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                result.append(os.path.join(root, file))\n",
    "    return result\n",
    "\n",
    "\n",
    "files = find_files_with_extension(data_path, extension)\n",
    "table = pd.read_csv(table_path)\n",
    "table['Acq Date'] = pd.to_datetime(table['Acq Date'], format='%m/%d/%Y')\n",
    "\n",
    "subs = []\n",
    "cohorts = []\n",
    "age = []\n",
    "sex = []\n",
    "iids = []\n",
    "spect_visit = []\n",
    "spect_date = []\n",
    "\n",
    "for idx, sub in enumerate(tqdm(table['Subject'].unique(), desc=\"refactoring\", leave=True)):\n",
    "    sub_rows = table[table['Subject'] == sub]\n",
    "    if len(sub_rows) > 1:\n",
    "        row_idx = sub_rows['Acq Date'].idxmin()\n",
    "        sub_row = table.loc[row_idx]\n",
    "    else:\n",
    "        sub_row = sub_rows.iloc[0]\n",
    "\n",
    "    if sub_row['Image Data ID'][0] == 'D':\n",
    "        iid = 'I' + sub_row['Image Data ID'][1:]\n",
    "    else:\n",
    "        iid = sub_row['Image Data ID']\n",
    "\n",
    "    list_idx = find_substring_in_list(iid, files)\n",
    "\n",
    "    save_dir = os.path.join(save_path, str(sub))\n",
    "    os.makedirs(save_dir)\n",
    "    shutil.copy(files[list_idx], os.path.join(save_dir, \"DaT.nii\"))\n",
    "\n",
    "    subs.append(sub)\n",
    "    cohorts.append(sub_row['Group'])\n",
    "    age.append(sub_row['Age'])\n",
    "    sex.append(sub_row['Sex'])\n",
    "    iids.append(sub_row['Image Data ID'])\n",
    "    spect_visit.append(sub_row['Visit'])\n",
    "    spect_date.append(sub_row['Acq Date'])\n",
    "\n",
    "sub_table = pd.DataFrame({'subject_number': subs, \n",
    "                          'cohort': cohorts,\n",
    "                          'age':age,\n",
    "                          'sex':sex,\n",
    "                          'spect_id':iids,\n",
    "                          'spect_visit':spect_visit,\n",
    "                          'spect_date':spect_date})\n",
    "sub_table.to_csv(table_save_path)\n",
    "\n",
    "print(\"refactoring done.\")\n",
    "print(f\"result files are saved in {save_path}\")\n",
    "print(f\"result table is saved in {table_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addac00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data class filtering\n",
    "\n",
    "data_path       = \"./data/DaT_nii_multi_inspection_filtering\"\n",
    "table_path      = \"./data/DaT_nii_multi_inspection_filtering.csv\"\n",
    "\n",
    "save_path       = \"./data/DaT_nii_multi_inspection_filtering_class_filtering\"\n",
    "table_save_path = \"./data/DaT_nii_multi_inspection_filtering_class_filtering.csv\"\n",
    "\n",
    "labels = ['Control', 'PD']\n",
    "############################################\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "subs = os.listdir(data_path)\n",
    "table = pd.read_csv(table_path, index_col=0)\n",
    "filtered_sub = table[~table['cohort'].isin(labels)]['subject_number']\n",
    "\n",
    "filtered_table = table[table['cohort'].isin(labels)]\n",
    "filtered_table.to_csv(table_save_path)\n",
    "\n",
    "shutil.copytree(data_path, save_path, dirs_exist_ok=True)\n",
    "\n",
    "for sub in tqdm(filtered_sub, desc=\"removing\"):\n",
    "    shutil.rmtree(os.path.join(save_path, str(sub)))\n",
    "\n",
    "print(\"class filtering done.\")\n",
    "print(f\"{len(filtered_sub)} data are filtered\")\n",
    "if len(filtered_sub) > 0:\n",
    "    if len(filtered_sub) > 10:\n",
    "        print(f\"filtered list: {str(filtered_sub[:5])[:-1] + ', ..., '+ str(filtered_sub[-5:])[1:]}\")\n",
    "    else:\n",
    "        print(f\"filtered list: {filtered_sub}\")\n",
    "\n",
    "print(f\"result files are saved in {save_path}\")\n",
    "print(f\"result table is saved in {table_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be662511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape filtering\n",
    "\n",
    "data_path       = \"./data/DaT_nii_multi_inspection_filtering_class_filtering\"\n",
    "table_path      = \"./data/DaT_nii_multi_inspection_filtering_class_filtering.csv\"\n",
    "\n",
    "save_path       = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering\"\n",
    "table_save_path = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering.csv\"\n",
    "\n",
    "shape = (91, 109, 91)\n",
    "############################################\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "subs = os.listdir(data_path)\n",
    "\n",
    "filtered_sub = []\n",
    "for idx, sub in enumerate(tqdm(subs, desc='shape filtering')):\n",
    "    dat_path = os.path.join(data_path, sub, \"DaT.nii\")\n",
    "    dat_nib = nib.load(dat_path)\n",
    "    if dat_nib.shape == shape:\n",
    "        dat_save_dir = os.path.join(save_path, sub)\n",
    "        os.makedirs(dat_save_dir, exist_ok=True)\n",
    "        dat_save_path = os.path.join(dat_save_dir, \"DaT.nii\")\n",
    "        shutil.copy(dat_path, dat_save_path)\n",
    "    else:\n",
    "        filtered_sub.append(sub)\n",
    "    pass\n",
    "\n",
    "sub_table = pd.read_csv(table_path, index_col=0)\n",
    "for sub in filtered_sub:\n",
    "    sub_table = sub_table[sub_table['subject_number'] != int(sub)]\n",
    "\n",
    "sub_table.to_csv(table_save_path)\n",
    "\n",
    "print(\"shape filtering done.\")\n",
    "print(f\"{len(filtered_sub)} data filtered: {filtered_sub}\")\n",
    "print(f\"result files are saved in {save_path}\")\n",
    "print(f\"result table is saved in {table_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data affine matrix reorientation\n",
    "\n",
    "ref_img_path = \"./data/atlas/PD25_T1_2mm.nii\"\n",
    "\n",
    "data_path    = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering\"\n",
    "save_path    = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering_reorient\"\n",
    "\n",
    "############################################\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "ref_nib = nib.load(ref_img_path)\n",
    "ref_affine = ref_nib.affine\n",
    "subs = os.listdir(data_path)\n",
    "for sub in tqdm(subs, desc='reorientation'):\n",
    "    dat_path = os.path.join(data_path, sub, \"DaT.nii\")\n",
    "    dat_nib = nib.load(dat_path)\n",
    "    dat_arr = dat_nib.get_fdata()\n",
    "    dat_header = dat_nib.header\n",
    "    re_orient_dat_nib = nib.Nifti1Image(dat_arr, affine=ref_affine, header=dat_header)\n",
    "    os.makedirs(os.path.join(save_path, sub), exist_ok=True)\n",
    "    nib.save(re_orient_dat_nib, os.path.join(save_path, sub, \"DaT.nii\"))\n",
    "\n",
    "print(f\"reorientation done. \")\n",
    "print(f\"result files are saved in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBR table merge\n",
    "\n",
    "table_path      = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering.csv\"\n",
    "data_path       = \"./data/DaT_nii_multi_inspection_filtering_class_filtering_shape_filtering_reorient\"\n",
    "\n",
    "save_path       = \"./data/DaT_preprocessed\"\n",
    "table_save_path = \"./data/DaT_preprocessed.csv\"\n",
    "\n",
    "############################################\n",
    "SBR_COLUMNS = [\n",
    "    \"DATSCAN_CAUDATE_R\",\n",
    "    \"DATSCAN_CAUDATE_L\",\n",
    "    \"DATSCAN_PUTAMEN_R\",\n",
    "    \"DATSCAN_PUTAMEN_L\",\n",
    "    \"DATSCAN_PUTAMEN_R_ANT\",\n",
    "    \"DATSCAN_PUTAMEN_L_ANT\",\n",
    "]\n",
    "\n",
    "table = pd.read_csv(table_path, index_col=0)\n",
    "sbr_table = pd.read_csv(sbr_table_path, index_col=None)\n",
    "\n",
    "merged_table = pd.merge(table, \n",
    "                        sbr_table[['PATNO', 'EVENT_ID', 'DATSCAN_CAUDATE_R', 'DATSCAN_CAUDATE_L', 'DATSCAN_PUTAMEN_R', 'DATSCAN_PUTAMEN_L', 'DATSCAN_PUTAMEN_R_ANT', 'DATSCAN_PUTAMEN_L_ANT']],\n",
    "                        left_on=['subject_number', 'spect_visit'],\n",
    "                        right_on=['PATNO', 'EVENT_ID'],\n",
    "                        how='inner'\n",
    "                        )\n",
    "\n",
    "no_sbr_list = set(table['subject_number'].to_list()) - set(merged_table['subject_number'].to_list())\n",
    "\n",
    "shutil.copytree(data_path, save_path)\n",
    "for sub in tqdm(no_sbr_list, desc=\"removing\"):\n",
    "    shutil.rmtree(os.path.join(save_path, str(sub)))\n",
    "\n",
    "merged_table = merged_table.drop(columns=['PATNO', 'EVENT_ID'])\n",
    "\n",
    "no_sbr_list = no_sbr_list.union(set(merged_table[merged_table[SBR_COLUMNS].isna().any(axis=1)]['subject_number'].to_list()))\n",
    "merged_table = merged_table.dropna(subset=SBR_COLUMNS)\n",
    "merged_table.to_csv(table_save_path)\n",
    "\n",
    "print(\"SBR merge done.\")\n",
    "print(f\"{len(no_sbr_list)} data filtered: {no_sbr_list}\")\n",
    "print(f\"result files are saved in {save_path}\")\n",
    "print(f\"result table is saved in {table_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parkinson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
